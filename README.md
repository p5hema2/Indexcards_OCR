# Indexcards_OCR
Python batch-processing workflow for digitized index cards using OpenRouter and Qwen3-VL. Automates OCR, metadata extraction, validation, error logging, and incremental CSV output to create structured records ready for import into collection management systems.

# üìá Index Card Digitization Workflow  
### Batch OCR & Metadata Extraction with OpenRouter + Qwen3-VL

This repository contains a Python-based batch workflow for processing digitized index cards (JPG). The script automates OCR, structured metadata extraction, validation, error handling, and incremental CSV output. It is designed for GLAM institutions (museums, archives, libraries, memorial sites) working to transform legacy card catalogs into standardized digital records.

---

## üöÄ Features

- **Batch-processing of JPG images**  
  Processes thousands of index cards in a single run.

- **LLM-powered OCR + metadata parsing**  
  Uses *OpenRouter* and the vision model **Qwen3-VL** to extract highly structured metadata fields.

- **Domain-focused extraction template**  
  Maps legacy card content to modern collection-management schemas (e.g., object name, provenance, acquisition data, measurements, classification, notes).

- **Fault-tolerant workflow**  
  - logs individual errors  
  - stores partial progress  
  - automatically moves problematic files to a separate folder  

- **Incremental CSV output**  
  Builds a master CSV that can be imported into museum or archive collection databases.

- **Extendable architecture**  
  Easily add:
  - custom fields  
  - new validation routines  
  - additional OCR preprocessing  
  - new output formats (JSON, XML, etc.)

---

## üìÅ Repository Structure

```
indexcard_ocr.py                                 (Main batch processing script)
config.py                                        (Configuration & Prompts)
requirements.txt                                 (Python dependencies)
/output_batches/                                 (Generated results)
/output_batches/json/                            (Individual JSON outputs)
/output_batches/csv/                             (Batch CSV outputs)
```


## üîß Requirements

- Python 3.10+
- An OpenRouter API key
- Dependencies: See `requirements.txt`



## ‚ñ∂Ô∏è Usage

- 1.) Place JPG images of the index cards into an input directory (default: `./input_batches`).
- 2.) Set your OpenRouter API key:
  ```bash
  export OPENROUTER_API_KEY=your_api_key_here
  ```
- 3.) Run the script:
  ```bash
  python indexcard_ocr.py
  ```
- 4.) Processed data will appear in `output_batches/`.

---

## üß† Workflow Overview

1. **Load & preprocess images**
Each JPG file is opened and optionally resized for efficient API transfer.

2. **Vision-LLM request to Qwen3-VL**
The script sends each image to OpenRouter with a structured extraction prompt defined in `config.py`.

3. **Structured response parsing**
LLM output is validated as JSON against a schema.

4. **Incremental CSV output**
Individual results are saved as JSON, and batch CSVs are generated. A master CSV aggregates all results.

5. **Fault-tolerant handling**
- Exponential backoff for rate limits (429).
- Checkpointing allows resuming interrupted batches.
- Robust error logging.

---

## üì¶ Example Output (JSON)

```
{
  "object": "Ceramic bowl",
  "inventory_number": "INV-2012-45",
  "origin": "Thuringia",
  "date_acquired": "1977-04-10",
  "collector": "Dr. H. Weiss",
  "measurements": "√ò 18 cm; height 7 cm",
  "material": "Ceramic",
  "notes": "Found during renovation of old farm estate."
}
```

---

## üèõÔ∏è Project Background
This workflow was developed at the Thuringian University and State Library (ThULB) to support a 2.5‚Äì3 year digitization initiative across GLAM institutions in Thuringia. Many museums and archives hold tens of thousands of legacy catalogue cards that contain irreplaceable information about objects, collections, and provenance ‚Äî yet these analog systems are increasingly inaccessible.

The goal of this workflow:

- rescue and preserve these historical metadata
- migrate them into modern digital collection databases
- support quality control, enrichment, and interoperability
- make hidden collections visible again
- This script forms the technical spine of that digitization effort.

---

## üçé macOS Compatibility
This workflow was designed and tested primarily on macOS systems. It supports macOS directory structures, file-handling conventions, and terminal environments, making it ideal for GLAM professionals who process large batches of digitized index cards on a Mac. The script also works seamlessly with JPG files generated by macOS or iOS devices.

---

## ‚ö†Ô∏è Important Notice: AI-Generated Code

This repository contains code that has been generated with the assistance of artificial intelligence. While the code should be functional, **the following steps are required before productive use**:

### Required Adjustments

| Area | Action |
|------|--------|
| **Naming Conventions** | Review and standardize variable, function, and class names according to your project guidelines |
| **File Paths** | Replace hardcoded paths with relative paths or configuration variables; test across different operating systems |
| **Libraries & Dependencies** | Validate all `import` statements and update `requirements.txt` or `package.json` with exact version numbers |
| **Configuration** | Check all magic strings and magic numbers; externalize these into configuration files |

### Recommendations

- Conduct code reviews, even for AI-generated code
- Create comprehensive unit tests
- Test in your specific environment
- Document any adjustments you've made

You use this code at your own risk.

## üìú License
This project is released under the MIT License.

---

## ü§ù Contributing
Contributions, improvements, and feature suggestions are welcome.
Please open an issue or submit a pull request.

---

## üì¨ Contact
For questions or collaboration requests, feel free to open an issue or reach out.

---
