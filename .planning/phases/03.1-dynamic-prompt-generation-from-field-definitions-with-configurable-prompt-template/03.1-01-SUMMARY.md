---
phase: 03.1
plan: 01
subsystem: backend-data-models-ocr-pipeline
tags: [prompt-template, data-models, json-schema, codegen, pydantic, ocr-engine]
dependency_graph:
  requires: []
  provides:
    - prompt_template field in all Template and Batch data model layers
    - OcrEngine._generate_prompt() with custom template rendering and {{fields}} substitution
    - prompt_template wired end-to-end: BatchCreate -> config.json -> run_ocr_task -> process_batch -> _generate_prompt
  affects:
    - packages/shared-types (schemas, generated TS and Python)
    - apps/backend models, batch_manager, ocr_engine, batches endpoint
tech_stack:
  added: []
  patterns:
    - JSON Schema as source of truth for all type changes
    - Optional[str] = None with .get() backward compat for config.json reads
    - {{fields}} placeholder substitution with append fallback
key_files:
  created: []
  modified:
    - packages/shared-types/schemas/template.schema.json
    - packages/shared-types/schemas/batch.schema.json
    - packages/shared-types/generated/ts/index.ts
    - packages/shared-types/generated/py/template.py
    - packages/shared-types/generated/py/batch.py
    - apps/backend/app/models/schemas.py
    - apps/backend/app/services/batch_manager.py
    - apps/backend/app/services/ocr_engine.py
    - apps/backend/app/api/api_v1/endpoints/batches.py
decisions:
  - "{{fields}} placeholder substitution with append fallback when absent: matches plan spec exactly"
  - "prompt_template read via config.get() in run_ocr_task: backward compat with existing config.json files"
  - "process_batch parameter added as keyword-only at end of signature: avoids breaking existing callers"
metrics:
  duration: ~4min
  completed_date: 2026-02-22
  tasks: 2
  files: 9
---

# Phase 03.1 Plan 01: Prompt Template Data Models and Pipeline Wiring Summary

**One-liner:** Added `prompt_template: Optional[str] = None` to all 5 data model types (JSON Schema, generated TS/Python, Pydantic) and wired it from BatchCreate through config.json through OcrEngine._generate_prompt() with {{fields}} substitution and default fallback.

## Tasks Completed

| Task | Name | Commit | Key Files |
|------|------|--------|-----------|
| 1 | Add prompt_template to JSON Schemas, run codegen, update Pydantic models | 34fa5de | template.schema.json, batch.schema.json, generated/ts/index.ts, generated/py/template.py, generated/py/batch.py, schemas.py |
| 2 | Wire prompt_template through backend pipeline (batch_manager, ocr_engine, batches endpoint) | 4b9d95c | batch_manager.py, ocr_engine.py, batches.py |

## What Was Built

### Data Models (Task 1)

Added `prompt_template` as an optional nullable string field to all five relevant model types:

- **template.schema.json:** Template, TemplateCreate, TemplateUpdate — all get `"anyOf": [{"type": "string"}, {"type": "null"}]` with `"default": null`
- **batch.schema.json:** BatchConfig, BatchCreate — same schema pattern
- **Codegen:** `node packages/shared-types/scripts/generate.mjs` regenerated `generated/ts/index.ts` (5 interfaces updated) and `generated/py/{template,batch}.py`
- **schemas.py:** All 5 Pydantic classes (`Template`, `TemplateCreate`, `TemplateUpdate`, `BatchConfig`, `BatchCreate`) get `prompt_template: Optional[str] = None`

### Backend Pipeline (Task 2)

Full end-to-end wiring:

1. **batch_manager.create_batch()** — signature extended with `prompt_template: Optional[str] = None`; written into `config_data` dict so config.json carries it.

2. **OcrEngine._generate_prompt()** — extended with `template: Optional[str] = None` parameter:
   - `template` provided AND contains `{{fields}}` → `template.replace("{{fields}}", fields_block)`
   - `template` provided WITHOUT `{{fields}}` → `template + "\n\n" + fields_block` (append fallback)
   - `template` is None → existing hardcoded German prompt (unchanged behavior)

3. **OcrEngine._call_vlm_api_resilient()** — extended with `prompt_template` parameter; passed to `_generate_prompt(fields, template=prompt_template)`.

4. **OcrEngine._process_card_sync()** — extended with `prompt_template`; forwarded to `_call_vlm_api_resilient()`.

5. **OcrEngine.process_card()** — extended with `prompt_template`; passed positionally to `_process_card_sync`.

6. **OcrEngine.process_batch()** — extended with `prompt_template: Optional[str] = None`; captured in `_run_batch` closure and passed to each `executor.submit(_process_card_sync, ..., prompt_template)`.

7. **run_ocr_task()** in batches.py — reads `prompt_template = config.get("prompt_template")` after reading config.json (`.get()` provides backward compat for old batches without the key); passed as `prompt_template=prompt_template` to `process_batch`.

8. **create_batch endpoint** — passes `prompt_template=batch_data.prompt_template` to `batch_manager.create_batch()`.

## Verification Results

| Check | Result |
|-------|--------|
| `grep -c prompt_template template.schema.json` | 3 (one per definition) |
| `grep -c prompt_template batch.schema.json` | 2 (BatchConfig + BatchCreate) |
| `grep -c prompt_template generated/ts/index.ts` | 5 (all 5 interfaces) |
| `grep -c prompt_template schemas.py` | 5 (all 5 Pydantic classes) |
| TypeScript `npx tsc --noEmit` | PASSED |
| `_generate_prompt(['Name','Date'], template='Extract: {{fields}}')` | Renders correctly |
| `_generate_prompt(['Name'])` with no template | Contains 'Experte' (default prompt) |
| `_generate_prompt(['Komponist'], template='No placeholder here.')` | Appends fields block |

## Deviations from Plan

None - plan executed exactly as written.

## Self-Check: PASSED

All 7 modified files confirmed present on disk. Both task commits (34fa5de, 4b9d95c) confirmed in git log.
