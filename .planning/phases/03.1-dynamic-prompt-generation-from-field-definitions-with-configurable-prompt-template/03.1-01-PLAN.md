---
phase: 03.1-dynamic-prompt-generation-from-field-definitions-with-configurable-prompt-template
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/shared-types/schemas/template.schema.json
  - packages/shared-types/schemas/batch.schema.json
  - packages/shared-types/generated/ts/index.ts
  - packages/shared-types/generated/py/template.py
  - packages/shared-types/generated/py/batch.py
  - apps/backend/app/models/schemas.py
  - apps/backend/app/services/batch_manager.py
  - apps/backend/app/services/ocr_engine.py
  - apps/backend/app/api/api_v1/endpoints/batches.py
autonomous: true

must_haves:
  truths:
    - "prompt_template field exists in Template, TemplateCreate, TemplateUpdate, BatchCreate, and BatchConfig data models"
    - "config.json written by create_batch() includes prompt_template value (null when not provided)"
    - "run_ocr_task reads prompt_template from config.json and passes it to process_batch"
    - "OcrEngine._generate_prompt() renders a custom template when prompt_template is non-null, falling back to the existing hardcoded prompt when null"
    - "Existing batches without prompt_template in config.json continue to work (backward compat via .get())"
  artifacts:
    - path: "packages/shared-types/schemas/template.schema.json"
      provides: "prompt_template field in Template, TemplateCreate, TemplateUpdate"
      contains: "prompt_template"
    - path: "packages/shared-types/schemas/batch.schema.json"
      provides: "prompt_template field in BatchConfig and BatchCreate"
      contains: "prompt_template"
    - path: "packages/shared-types/generated/ts/index.ts"
      provides: "TypeScript interfaces with prompt_template"
      contains: "prompt_template"
    - path: "apps/backend/app/models/schemas.py"
      provides: "Pydantic models with prompt_template: Optional[str] = None"
      contains: "prompt_template"
    - path: "apps/backend/app/services/ocr_engine.py"
      provides: "_generate_prompt with template parameter and {{fields}} substitution"
      contains: "template"
    - path: "apps/backend/app/api/api_v1/endpoints/batches.py"
      provides: "prompt_template read from config.json and passed to process_batch"
      contains: "prompt_template"
  key_links:
    - from: "apps/backend/app/api/api_v1/endpoints/batches.py"
      to: "apps/backend/app/services/ocr_engine.py"
      via: "prompt_template parameter passed through process_batch"
      pattern: "prompt_template=prompt_template"
    - from: "apps/backend/app/api/api_v1/endpoints/batches.py"
      to: "apps/backend/app/services/batch_manager.py"
      via: "prompt_template from BatchCreate body passed to create_batch()"
      pattern: "prompt_template=batch_data\\.prompt_template"
    - from: "apps/backend/app/services/ocr_engine.py"
      to: "config.json"
      via: "_generate_prompt uses template param for {{fields}} substitution"
      pattern: "template\\.replace.*fields"
---

<objective>
Add `prompt_template` field to all data models (JSON Schema, generated types, backend Pydantic) and wire it through the entire backend processing pipeline from batch creation through OCR prompt generation.

Purpose: Enable users to provide a custom prompt template that controls how the VLM is instructed, replacing the hardcoded German prompt while preserving backward compatibility for existing batches and the null-means-default fallback.

Output: Updated schemas, generated types, Pydantic models, batch_manager, ocr_engine, and batches endpoint all carrying `prompt_template` end-to-end.
</objective>

<execution_context>
@/Users/martinhess/.claude/get-shit-done/workflows/execute-plan.md
@/Users/martinhess/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03.1-dynamic-prompt-generation-from-field-definitions-with-configurable-prompt-template/03.1-RESEARCH.md
@packages/shared-types/schemas/template.schema.json
@packages/shared-types/schemas/batch.schema.json
@packages/shared-types/scripts/generate.mjs
@apps/backend/app/models/schemas.py
@apps/backend/app/services/batch_manager.py
@apps/backend/app/services/ocr_engine.py
@apps/backend/app/api/api_v1/endpoints/batches.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add prompt_template to JSON Schemas, run codegen, update Pydantic models</name>
  <files>
    packages/shared-types/schemas/template.schema.json
    packages/shared-types/schemas/batch.schema.json
    apps/backend/app/models/schemas.py
  </files>
  <action>
1. Edit `packages/shared-types/schemas/template.schema.json`:
   - Add `prompt_template` to **Template** properties:
     ```json
     "prompt_template": {
       "anyOf": [{"type": "string"}, {"type": "null"}],
       "default": null,
       "title": "Prompt Template",
       "description": "Custom VLM prompt template with {{fields}} placeholder. Null means use default."
     }
     ```
     Do NOT add it to `required` array (it's optional).
   - Add the same `prompt_template` property to **TemplateCreate** (not required).
   - Add the same `prompt_template` property to **TemplateUpdate** (not required, default null — same pattern as existing `name` and `fields` in TemplateUpdate).

2. Edit `packages/shared-types/schemas/batch.schema.json`:
   - Add `prompt_template` to **BatchConfig** properties (same schema as above). Do NOT add to `required`.
   - Add `prompt_template` to **BatchCreate** properties (same schema as above). Do NOT add to `required`.

3. Run `turbo generate` from repo root to regenerate `generated/ts/index.ts` and `generated/py/*.py`. Verify the generated TypeScript file contains `prompt_template` in the Template, TemplateCreate, TemplateUpdate, BatchConfig, and BatchCreate interfaces.

4. Edit `apps/backend/app/models/schemas.py`:
   - Add `prompt_template: Optional[str] = None` to:
     - `Template` class (after `fields`)
     - `TemplateCreate` class (after `fields`)
     - `TemplateUpdate` class (after `fields`)
     - `BatchCreate` class (after `fields`)
     - `BatchConfig` class (after `fields`, also update the comment to remove "More to follow")
  </action>
  <verify>
    - `grep -c prompt_template packages/shared-types/schemas/template.schema.json` returns 3 (one per definition)
    - `grep -c prompt_template packages/shared-types/schemas/batch.schema.json` returns 2 (BatchConfig + BatchCreate)
    - `grep -c prompt_template packages/shared-types/generated/ts/index.ts` returns 5 (Template, TemplateCreate, TemplateUpdate, BatchConfig, BatchCreate)
    - `grep -c prompt_template apps/backend/app/models/schemas.py` returns 5
    - `cd apps/frontend && npx tsc --noEmit` passes (TypeScript compilation with new types)
  </verify>
  <done>All five data model types (Template, TemplateCreate, TemplateUpdate, BatchConfig, BatchCreate) contain prompt_template as an optional nullable string field across JSON Schema source, generated TypeScript, and backend Pydantic models.</done>
</task>

<task type="auto">
  <name>Task 2: Wire prompt_template through backend pipeline (batch_manager, ocr_engine, batches endpoint)</name>
  <files>
    apps/backend/app/services/batch_manager.py
    apps/backend/app/services/ocr_engine.py
    apps/backend/app/api/api_v1/endpoints/batches.py
  </files>
  <action>
1. Edit `apps/backend/app/services/batch_manager.py`:
   - Update `create_batch()` signature to accept `prompt_template: Optional[str] = None` parameter.
   - Add `"prompt_template": prompt_template` to the `config_data` dict (after `"fields"` line). When None, JSON serializes it as `null` which is fine.
   - Update `_record_history()` — no changes needed (history doesn't need prompt_template).

2. Edit `apps/backend/app/services/ocr_engine.py`:
   - Update `_generate_prompt()` signature to accept `template: Optional[str] = None`.
   - When `template` is not None:
     - If `"{{fields}}"` is present in template, do `template.replace("{{fields}}", fields_block)` and return.
     - If `"{{fields}}"` is NOT present, append `"\n\n" + fields_block` to the template and return.
   - When `template` is None, keep the existing hardcoded prompt behavior unchanged.
   - Update `_call_vlm_api_resilient()` signature to accept `prompt_template: Optional[str] = None`.
   - Change the prompt line to: `prompt = self._generate_prompt(fields, template=prompt_template) if fields else settings.EXTRACTION_PROMPT`
   - Update `_process_card_sync()` signature to accept `prompt_template: Optional[str] = None`.
   - Pass `prompt_template=prompt_template` to `_call_vlm_api_resilient()`.
   - Update `process_card()` async wrapper to accept and pass `prompt_template`.
   - Update `process_batch()` signature to accept `prompt_template: Optional[str] = None`.
   - In `_run_batch()` inner function, update the `executor.submit()` call to pass `prompt_template` to `_process_card_sync()`:
     ```python
     futures = {
         executor.submit(self._process_card_sync, img, batch_name, fields, max_size, prompt_template): img
         for img in files_to_process
     }
     ```
     Note: `_process_card_sync` signature must accept prompt_template as the 5th positional or keyword arg. Use keyword to be safe: update the submit call to use kwargs if cleaner — but positional is fine if the signature order is `(self, image_path, batch_name, fields, max_size, prompt_template)`.

3. Edit `apps/backend/app/api/api_v1/endpoints/batches.py`:
   - In `run_ocr_task()`, after `fields = config.get("fields")`, add: `prompt_template = config.get("prompt_template")` — using `.get()` for backward compat with old config.json files that lack the key.
   - Pass `prompt_template=prompt_template` to `ocr_engine.process_batch()`.
   - In `create_batch()` endpoint function, pass `prompt_template=batch_data.prompt_template` to `batch_manager.create_batch()`.
  </action>
  <verify>
    - `grep -n "prompt_template" apps/backend/app/services/batch_manager.py` shows the parameter in create_batch signature and in config_data dict.
    - `grep -n "prompt_template" apps/backend/app/services/ocr_engine.py` shows it in _generate_prompt, _call_vlm_api_resilient, _process_card_sync, process_card, process_batch, and _run_batch.
    - `grep -n "prompt_template" apps/backend/app/api/api_v1/endpoints/batches.py` shows it read from config.json and passed to both batch_manager.create_batch and ocr_engine.process_batch.
    - `cd apps/backend && uv run python -c "from app.services.ocr_engine import OcrEngine; e = OcrEngine(); print(e._generate_prompt(['Name','Date'], template='Extract: {{fields}}'))"` prints `Extract: 1. **Name**:... 2. **Date**:...`
    - `cd apps/backend && uv run python -c "from app.services.ocr_engine import OcrEngine; e = OcrEngine(); p = e._generate_prompt(['Name']); print('Experte' in p)"` prints `True` (default prompt still works).
  </verify>
  <done>prompt_template flows end-to-end: BatchCreate body -> batch_manager.create_batch -> config.json -> run_ocr_task reads it -> process_batch -> _process_card_sync -> _call_vlm_api_resilient -> _generate_prompt renders custom template or falls back to default. Backward compat with old config.json files is maintained via .get().</done>
</task>

</tasks>

<verification>
1. JSON Schema source files contain prompt_template in all 5 definitions.
2. Generated TypeScript types match the schema (turbo generate ran successfully).
3. Backend Pydantic models match the schema.
4. batch_manager.create_batch() writes prompt_template to config.json.
5. run_ocr_task() reads prompt_template from config.json via .get() (backward compat).
6. OcrEngine._generate_prompt() accepts and renders custom templates with {{fields}} substitution.
7. OcrEngine._generate_prompt() returns existing hardcoded prompt when template is None.
8. TypeScript compilation passes (npx tsc --noEmit).
</verification>

<success_criteria>
- All 5 data model types carry prompt_template across all layers (schema, TS, Pydantic).
- Custom template with {{fields}} placeholder is correctly rendered by _generate_prompt().
- Missing {{fields}} in template triggers append fallback.
- Null/absent prompt_template triggers the existing default prompt.
- Old config.json files without prompt_template key do not cause errors.
</success_criteria>

<output>
After completion, create `.planning/phases/03.1-dynamic-prompt-generation-from-field-definitions-with-configurable-prompt-template/03.1-01-SUMMARY.md`
</output>
