# Phase 03.1: Dynamic Prompt Generation from Field Definitions with Configurable Prompt Template - Research

**Researched:** 2026-02-22
**Domain:** VLM prompt engineering, FastAPI backend extension, React UI extension, per-template storage
**Confidence:** HIGH (based on direct codebase inspection; no external library research required — this is a pure codebase-internal feature)

---

## Summary

The existing system already has partial infrastructure for dynamic prompt generation. `OcrEngine._generate_prompt()` in `apps/backend/app/services/ocr_engine.py` builds a prompt at call time from a `List[str]` of field names. However the generated template is entirely hardcoded in Python — the preamble ("Du bist ein Experte..."), the field-entry format string, and the output-format instruction are all baked in. Users have no way to customise any of these parts.

The current `Template` model (stored in `data/templates.json`) holds only `id`, `name`, and `fields: List[str]`. There is no `prompt_template` field anywhere in the schema, the backend Pydantic models, or the shared JSON Schema source files. The `BatchConfig` / `config.json` written to each batch directory likewise stores only `fields`. The Configure step UI in `apps/frontend/src/features/configure/FieldManager.tsx` and `TemplateSelector.tsx` has no prompt-editing surface.

The work for this phase therefore spans three layers: (1) extend the data model to carry an optional `prompt_template` string, (2) wire that string through the backend generation pipeline, and (3) surface a template editor in the Configure step UI. The shared-types JSON Schema is the single source of truth for the API contract, so schema edits and a subsequent `turbo generate` run are required before touching any generated files.

**Primary recommendation:** Extend the `Template` schema with an optional `prompt_template` field, propagate it through `BatchConfig` / `config.json` / `_generate_prompt()`, and add a collapsible textarea editor in the Configure step with a live preview of the rendered prompt.

---

## What Already Exists (HIGH confidence — direct code inspection)

### Dynamic field injection — already implemented

`OcrEngine._generate_prompt(fields: List[str]) -> str` in `apps/backend/app/services/ocr_engine.py` (lines 78–94) already constructs a prompt from an arbitrary field list:

```python
def _generate_prompt(self, fields: List[str]) -> str:
    fields_description = "\n".join(
        [f"{i+1}. **{field}**: Extrahiere den Wert für das Feld '{field}'."
         for i, field in enumerate(fields)]
    )
    return f"""Du bist ein Experte...\n\n**Extrahiere folgende Felder:**\n{fields_description}\n\n..."""
```

This is called at `_call_vlm_api_resilient()` line 104:
```python
prompt = self._generate_prompt(fields) if fields else settings.EXTRACTION_PROMPT
```

So field names already flow from the UI through `BatchCreate.fields` → `BatchManager.create_batch()` → `config.json` → `run_ocr_task()` reads `config.json` → passed as `fields=` to `ocr_engine.process_batch()` → `process_card()` → `_call_vlm_api_resilient()` → `_generate_prompt()`.

### What is missing

1. **No `prompt_template` field** anywhere in the data model. The preamble and field-line format are hardcoded strings in Python. Users cannot change what the AI is told beyond the field list.
2. **No UI for editing the prompt template** — the Configure step only allows defining field labels.
3. **`config.json` does not store a prompt template** — it only stores `fields` and `custom_name`.
4. **`Template` model does not carry a prompt template** — templates save only field lists, not the instruction text.

---

## Data Flow Map (current state)

```
[UI: FieldManager]
   fields: MetadataField[]
        |
        v
[POST /api/v1/batches/] BatchCreate { custom_name, session_id, fields: string[] }
        |
        v
[BatchManager.create_batch()]
   writes config.json: { custom_name, fields, created_at }
        |
        v
[run_ocr_task() — batches.py]
   reads config.json → fields: list[str]
        |
        v
[ocr_engine.process_batch(fields=fields)]
        |
        v
[OcrEngine._generate_prompt(fields)]
   hardcoded preamble + field lines + output instruction
        |
        v
[OpenRouter API call with assembled prompt]
```

---

## What Needs to Change

### Layer 1: JSON Schema (source of truth)

File: `packages/shared-types/schemas/template.schema.json`

Add optional `prompt_template` to `Template`, `TemplateCreate`, `TemplateUpdate`:

```json
"prompt_template": {
  "anyOf": [{"type": "string"}, {"type": "null"}],
  "default": null,
  "title": "Prompt Template",
  "description": "Handlebars-style template with {{fields}} placeholder. If null, default template is used."
}
```

File: `packages/shared-types/schemas/batch.schema.json`

Add optional `prompt_template` to `BatchConfig` and `BatchCreate`:

```json
"prompt_template": {
  "anyOf": [{"type": "string"}, {"type": "null"}],
  "default": null,
  "title": "Prompt Template"
}
```

After editing schemas: run `turbo generate` to regenerate `generated/ts/index.ts` and `generated/py/*.py`. Do NOT edit generated files directly.

### Layer 2: Backend Pydantic models

File: `apps/backend/app/models/schemas.py`

`Template`, `TemplateCreate`, `TemplateUpdate`, `BatchCreate`, `BatchConfig` each gain:
```python
prompt_template: Optional[str] = None
```

Note: the generated Pydantic in `packages/shared-types/generated/py/` is for reference/validation; the backend's own `schemas.py` must be updated separately (it does not import from the generated package currently).

### Layer 3: Template service persistence

File: `apps/backend/app/services/template_service.py`

`create_template()` and `update_template()` already use Pydantic `.dict()` serialization — once the model field is added, persistence is automatic. No logic changes needed.

### Layer 4: Batch config.json

File: `apps/backend/app/services/batch_manager.py`

`create_batch()` writes `config_data` dict. Add:
```python
config_data = {
    "custom_name": custom_name,
    "fields": fields or settings.FIELD_KEYS,
    "prompt_template": prompt_template,   # new
    "created_at": datetime.now().isoformat()
}
```

`create_batch()` signature gains: `prompt_template: Optional[str] = None`

### Layer 5: OCR engine — configurable template rendering

File: `apps/backend/app/services/ocr_engine.py`

`_generate_prompt()` gains an optional `template: Optional[str] = None` parameter. When provided, replace the hardcoded format string with the user-supplied template, substituting a `{{fields}}` placeholder with the rendered field list.

Recommended placeholder approach: simple Python `str.replace()` with `{{fields}}` — no third-party templating library needed:

```python
def _generate_prompt(self, fields: List[str], template: Optional[str] = None) -> str:
    fields_block = "\n".join(
        [f"{i+1}. **{field}**: Extrahiere den Wert für das Feld '{field}'."
         for i, field in enumerate(fields)]
    )
    if template:
        return template.replace("{{fields}}", fields_block)
    # default behaviour unchanged
    return f"""Du bist ein Experte...\n\n**Extrahiere folgende Felder:**\n{fields_block}\n\n..."""
```

`_call_vlm_api_resilient()` passes the template through:
```python
prompt = self._generate_prompt(fields, template=prompt_template) if fields else settings.EXTRACTION_PROMPT
```

`_process_card_sync()` and `process_batch()` gain `prompt_template: Optional[str] = None` parameters.

`run_ocr_task()` in `batches.py` reads `prompt_template` from `config.json`.

### Layer 6: API endpoint

File: `apps/backend/app/api/api_v1/endpoints/batches.py`

`BatchCreate` body already flows through to `batch_manager.create_batch()`. Pass the new `prompt_template` field.

### Layer 7: Frontend — Configure step UI

File: `apps/frontend/src/features/configure/ConfigureStep.tsx` (or a new `PromptTemplateEditor.tsx`)

Add a collapsible "Prompt Template" section below the `FieldManager`. Contains:
- A `<textarea>` showing the current template (default pre-populated with the default template text).
- A `{{fields}}` placeholder hint.
- A live preview panel showing what the prompt would look like with the current fields substituted in.

The template string is stored in Zustand `wizardStore` alongside `fields`:

```typescript
// in wizardStore.ts
promptTemplate: string | null;
setPromptTemplate: (t: string | null) => void;
```

When saving a template via `SaveTemplateDialog`, `prompt_template` is included in the `TemplateCreate` payload.

When loading a template via `TemplateSelector`, `prompt_template` is applied to the store.

When submitting `createBatchMutation`, `prompt_template` is included in the `BatchCreate` payload.

---

## Standard Stack

No new libraries are required. This phase is a pure extension of existing patterns.

### Core (all already installed)
| Component | Location | Current Version |
|-----------|----------|-----------------|
| FastAPI + Pydantic v2 | `apps/backend` | existing |
| React + TypeScript | `apps/frontend` | existing |
| Zustand | `apps/frontend` | existing |
| TanStack Query | `apps/frontend` | existing |
| JSON Schema codegen | `packages/shared-types` | existing |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| `str.replace("{{fields}}", ...)` | Jinja2 | Jinja2 is a full dep with security surface; `str.replace` is sufficient for a single-placeholder template |
| `str.replace("{{fields}}", ...)` | Python f-strings | f-strings require `eval`-style execution of user input — never appropriate |
| Simple textarea | CodeMirror/Monaco editor | Overkill; plain textarea with monospace font is sufficient for a one-field prompt template |

---

## Architecture Patterns

### Recommended Project Structure Changes

No new files strictly required. Changes are confined to:
```
packages/shared-types/schemas/
├── batch.schema.json         # add prompt_template to BatchConfig, BatchCreate
└── template.schema.json      # add prompt_template to Template, TemplateCreate, TemplateUpdate

apps/backend/app/
├── models/schemas.py          # add prompt_template field to 4 Pydantic models
├── core/config.py             # add DEFAULT_PROMPT_TEMPLATE setting (optional, good practice)
├── services/
│   ├── batch_manager.py       # pass prompt_template through create_batch()
│   ├── ocr_engine.py          # _generate_prompt() + _process_card_sync() + process_batch()
│   └── template_service.py    # no logic changes; model changes propagate automatically
└── api/api_v1/endpoints/
    └── batches.py             # read prompt_template from BatchCreate body → batch_manager

apps/frontend/src/
├── store/wizardStore.ts       # add promptTemplate: string | null + setPromptTemplate
├── features/configure/
│   ├── ConfigureStep.tsx      # pass promptTemplate in createBatchMutation payload
│   ├── FieldManager.tsx       # add PromptTemplateEditor section (inline or separate component)
│   ├── PromptTemplateEditor.tsx  # NEW: textarea + placeholder hint + live preview
│   └── TemplateSelector.tsx   # apply prompt_template when loading a template
└── api/
    ├── templatesApi.ts        # include prompt_template in create/update mutations
    └── batchesApi.ts          # include prompt_template in BatchCreate payload
```

### Pattern 1: Template Placeholder Substitution (Python)

**What:** Replace `{{fields}}` in the user-supplied template string with the rendered field-description block before sending to the VLM.

**When to use:** Any time `prompt_template` is non-null and `fields` list is non-empty.

```python
# apps/backend/app/services/ocr_engine.py

DEFAULT_FIELDS_FORMAT = "{i}. **{field}**: Extrahiere den Wert für das Feld '{field}'."

def _render_fields_block(self, fields: List[str]) -> str:
    return "\n".join(
        DEFAULT_FIELDS_FORMAT.format(i=i+1, field=field)
        for i, field in enumerate(fields)
    )

def _generate_prompt(self, fields: List[str], template: Optional[str] = None) -> str:
    fields_block = self._render_fields_block(fields)
    if template:
        if "{{fields}}" not in template:
            # Fallback: append fields block at end if placeholder missing
            return template.rstrip() + "\n\n" + fields_block
        return template.replace("{{fields}}", fields_block)
    # Default hardcoded prompt (current behaviour)
    return (
        "Du bist ein Experte für die Digitalisierung historischer Archivkarteikarten...\n\n"
        "**Extrahiere folgende Felder:**\n"
        f"{fields_block}\n\n"
        "Falls ein Feld nicht vorhanden...\n\n"
        "**AUSGABEFORMAT:** Antworte NUR mit einem validen JSON-Objekt.\n"
    )
```

### Pattern 2: Live Preview in React

**What:** Show the user what the full prompt looks like in real time as they edit fields or the template.

**When to use:** In the `PromptTemplateEditor` component, computed from current `fields` and `promptTemplate` Zustand state.

```typescript
// Derived preview — no API call needed
function renderPreview(template: string, fields: MetadataField[]): string {
  const fieldsBlock = fields
    .map((f, i) => `${i + 1}. **${f.label}**: Extrahiere den Wert für das Feld '${f.label}'.`)
    .join('\n');
  if (!template.includes('{{fields}}')) {
    return template + '\n\n' + fieldsBlock;
  }
  return template.replace('{{fields}}', fieldsBlock);
}
```

### Pattern 3: Zustand Store Extension

**What:** Add `promptTemplate` alongside `fields` in `wizardStore.ts`.

```typescript
// Additional state in WizardState interface
promptTemplate: string | null;
setPromptTemplate: (t: string | null) => void;

// In create() body
promptTemplate: null,
setPromptTemplate: (promptTemplate) => set({ promptTemplate }),

// In resetWizard
promptTemplate: null,

// In partialize (persist to localStorage)
promptTemplate: state.promptTemplate,
```

### Anti-Patterns to Avoid

- **Editing generated files directly:** `generated/ts/index.ts` and `generated/py/*.py` are outputs of `turbo generate`. Always edit `.schema.json` and regenerate.
- **Storing the rendered prompt in `config.json`:** Store only the raw template. The engine renders it at call time so field changes don't require re-saving the batch.
- **Requiring a non-null template:** Template must be optional with `null` = use default. Many users will not need customisation; forcing them to deal with a template creates friction.
- **Server-side template validation:** The prompt template is a freeform string. Validating beyond "is it a string?" adds no safety for an internal-use tool.
- **Using Jinja2 or another engine:** `str.replace("{{fields}}", ...)` is sufficient, avoids a new Python dependency, and eliminates template injection risks.

---

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| TypeScript types for new fields | Manual edits to `generated/ts/index.ts` | Edit `.schema.json` + `turbo generate` | Generated files are overwritten on next codegen; manual edits are always lost |
| Pydantic models for new fields | Manual edits to `generated/py/*.py` | Edit `.schema.json` + `turbo generate` | Same; generated files are not the live backend models anyway |
| Template engine for `{{fields}}` | Jinja2, Mustache, Handlebars | Python `str.replace()` | Single placeholder; no conditionals, loops, or filters needed |
| API for previewing rendered prompt | New `/preview-prompt` endpoint | Client-side JS computation | Prompt rendering is pure string transformation; no server state needed |

**Key insight:** The primary complexity in this phase is not algorithmic but organisational — ensuring the `prompt_template` value flows correctly through all six layers without being dropped or shadowed at any point.

---

## Common Pitfalls

### Pitfall 1: Forgetting `turbo generate` after schema edits

**What goes wrong:** `generated/ts/index.ts` is stale. Frontend TypeScript compiler doesn't see the new `prompt_template` field and either accepts `undefined` silently or raises a type error only at runtime.

**Why it happens:** Developers edit `schemas/*.schema.json` and then manually edit `apps/backend/app/models/schemas.py` correctly, but forget to run codegen, so the shared TS types stay out of sync.

**How to avoid:** Make schema edits the first task. Run `turbo generate` immediately. Verify `generated/ts/index.ts` contains the new field before touching any application code.

**Warning signs:** TypeScript type error referencing `prompt_template` being `unknown`, or a lint warning that a property doesn't exist on the type.

---

### Pitfall 2: `prompt_template` silently dropped at `BatchCreate → config.json`

**What goes wrong:** The field is added to `BatchCreate` Pydantic model but `batch_manager.create_batch()` is not updated to accept and write it. The value reaches the endpoint but is not persisted. When `run_ocr_task()` reads `config.json`, `prompt_template` is missing and falls back to the hardcoded default.

**Why it happens:** `create_batch()` has its own explicit `config_data` dict construction — it doesn't auto-serialize from a Pydantic model.

**How to avoid:** Update `batch_manager.create_batch()` signature and `config_data` dict in the same commit as the Pydantic model change. Verify by inspecting `data/batches/<batch_name>/config.json` after a test run.

**Warning signs:** Prompt template appears to do nothing despite being set in the UI.

---

### Pitfall 3: Missing `{{fields}}` placeholder in user template

**What goes wrong:** User writes a custom template but omits `{{fields}}`. The rendered prompt contains no field enumeration. The VLM returns either an empty JSON object or a freeform response that fails validation.

**Why it happens:** Users writing templates may not know the placeholder convention.

**How to avoid:** Two mitigations: (1) Show a clear placeholder hint in the UI ("Use `{{fields}}` where you want the field list to appear"). (2) Backend fallback: if `{{fields}}` is not present in the template, append the fields block unconditionally.

**Warning signs:** VLM returns empty JSON or freeform text instead of structured extraction.

---

### Pitfall 4: Template saved without `prompt_template` when loading from `TemplateSelector`

**What goes wrong:** `TemplateSelector.handleSelectTemplate()` currently sets only `fields` into Zustand state. If `promptTemplate` is not also set, loading a template resets the prompt editor to the default while preserving whatever the user had typed.

**Why it happens:** `handleSelectTemplate` was written before `promptTemplate` existed.

**How to avoid:** Update `handleSelectTemplate` to also call `setPromptTemplate(template.prompt_template ?? null)`.

**Warning signs:** Loading a saved template correctly sets fields but the prompt template textarea stays at whatever the user had entered.

---

### Pitfall 5: `config.json` backward compatibility

**What goes wrong:** Existing batches in `data/batches/*/config.json` do not have a `prompt_template` key. When `run_ocr_task()` reads them, it must handle the missing key gracefully.

**Why it happens:** The field is new; old batches pre-date it.

**How to avoid:** Use `.get("prompt_template")` (not `config["prompt_template"]`) when reading from `config.json`. The `None` fallback triggers the existing default-prompt code path. This is already the pattern used for `fields` in `run_ocr_task()` (line 31: `fields = config.get("fields")`).

**Warning signs:** `KeyError: 'prompt_template'` when retrying or resuming old batches.

---

## Code Examples

### `_generate_prompt` with configurable template

```python
# apps/backend/app/services/ocr_engine.py

def _generate_prompt(self, fields: List[str], template: Optional[str] = None) -> str:
    """Generiert einen Prompt aus Feldern und optionalem Template."""
    fields_block = "\n".join(
        [f"{i+1}. **{field}**: Extrahiere den Wert für das Feld '{field}'."
         for i, field in enumerate(fields)]
    )
    if template:
        if "{{fields}}" in template:
            return template.replace("{{fields}}", fields_block)
        # No placeholder: append fields block to ensure they are included
        return template.rstrip() + "\n\n" + fields_block

    # Default prompt (current hardcoded behaviour)
    return (
        "Du bist ein Experte für die Digitalisierung historischer Archivkarteikarten aus dem Bereich Musik.\n\n"
        "Deine Aufgabe ist es, die Informationen von der Karteikarte präzise zu extrahieren.\n"
        "Achte besonders auf die Handschrift und mögliche Streichungen.\n\n"
        "**Extrahiere folgende Felder:**\n"
        f"{fields_block}\n\n"
        "Falls ein Feld nicht auf der Karte vorhanden ist oder nicht entziffert werden kann, "
        "verwende einen leeren String (\"\").\n"
        "Ändere nichts an der Schreibweise historischer Begriffe, außer bei offensichtlichen Tippfehlern.\n\n"
        "**AUSGABEFORMAT:** Antworte NUR mit einem validen JSON-Objekt.\n"
    )
```

### Extended Pydantic models

```python
# apps/backend/app/models/schemas.py (additions)

class Template(BaseModel):
    id: str
    name: str
    fields: List[str]
    prompt_template: Optional[str] = None   # NEW

class TemplateCreate(BaseModel):
    name: str
    fields: List[str]
    prompt_template: Optional[str] = None   # NEW

class TemplateUpdate(BaseModel):
    name: Optional[str] = None
    fields: Optional[List[str]] = None
    prompt_template: Optional[str] = None   # NEW

class BatchCreate(BaseModel):
    custom_name: str
    session_id: str
    fields: Optional[List[str]] = None
    prompt_template: Optional[str] = None   # NEW

class BatchConfig(BaseModel):
    fields: List[str]
    prompt_template: Optional[str] = None   # NEW
```

### `batch_manager.create_batch()` signature and config_data

```python
# apps/backend/app/services/batch_manager.py

def create_batch(
    self,
    custom_name: str,
    session_id: str,
    fields: Optional[List[str]] = None,
    prompt_template: Optional[str] = None,   # NEW
) -> str:
    ...
    config_data = {
        "custom_name": custom_name,
        "fields": fields or settings.FIELD_KEYS,
        "prompt_template": prompt_template,   # NEW — None is JSON null
        "created_at": datetime.now().isoformat()
    }
```

### `run_ocr_task()` reading prompt_template from config.json

```python
# apps/backend/app/api/api_v1/endpoints/batches.py

fields = None
prompt_template = None   # NEW
if config_path.exists():
    with open(config_path, "r") as f:
        config = json.load(f)
        fields = config.get("fields")
        prompt_template = config.get("prompt_template")   # NEW — None if missing (backward compat)

await ocr_engine.process_batch(
    batch_dir=batch_path,
    fields=fields,
    prompt_template=prompt_template,   # NEW
    ...
)
```

### Zustand store extension

```typescript
// apps/frontend/src/store/wizardStore.ts

// In WizardState interface:
promptTemplate: string | null;
setPromptTemplate: (t: string | null) => void;

// In initialState:
promptTemplate: null,

// In create() body:
setPromptTemplate: (promptTemplate) => set({ promptTemplate }),

// In resetWizard:
promptTemplate: null,

// In partialize:
promptTemplate: state.promptTemplate,
```

### PromptTemplateEditor component skeleton

```typescript
// apps/frontend/src/features/configure/PromptTemplateEditor.tsx

import React, { useState } from 'react';
import { useWizardStore } from '../../store/wizardStore';

const DEFAULT_TEMPLATE = `Du bist ein Experte für die Digitalisierung historischer Archivkarteikarten.

**Extrahiere folgende Felder:**
{{fields}}

Falls ein Feld nicht vorhanden ist, verwende "".
**AUSGABEFORMAT:** Antworte NUR mit einem validen JSON-Objekt.`;

export const PromptTemplateEditor: React.FC = () => {
  const { fields, promptTemplate, setPromptTemplate } = useWizardStore();
  const [showPreview, setShowPreview] = useState(false);

  const effectiveTemplate = promptTemplate ?? DEFAULT_TEMPLATE;

  const renderedPreview = React.useMemo(() => {
    const fieldsBlock = fields
      .map((f, i) => `${i + 1}. **${f.label}**: Extrahiere den Wert für das Feld '${f.label}'.`)
      .join('\n');
    if (!effectiveTemplate.includes('{{fields}}')) {
      return effectiveTemplate + '\n\n' + fieldsBlock;
    }
    return effectiveTemplate.replace('{{fields}}', fieldsBlock);
  }, [fields, effectiveTemplate]);

  return (
    <div className="space-y-4">
      <div className="flex items-center justify-between">
        <h3 className="text-lg font-serif text-archive-ink">Prompt Template</h3>
        <button onClick={() => setShowPreview(v => !v)} className="text-sm text-archive-sepia underline">
          {showPreview ? 'Edit' : 'Preview'}
        </button>
      </div>

      <p className="text-xs text-archive-ink/60 italic">
        Use <code className="bg-parchment-dark/10 px-1 rounded">{'{{fields}}'}</code> as the placeholder
        where the field list should appear. Leave blank to use the default template.
      </p>

      {showPreview ? (
        <pre className="text-xs font-mono bg-parchment-dark/5 border border-parchment-dark/30 rounded p-4 whitespace-pre-wrap">
          {renderedPreview}
        </pre>
      ) : (
        <textarea
          className="w-full h-48 font-mono text-sm bg-parchment-light/30 border border-parchment-dark/50 rounded p-3 focus:outline-none focus:border-archive-sepia/50 resize-y"
          value={effectiveTemplate}
          onChange={(e) => setPromptTemplate(e.target.value || null)}
          placeholder={DEFAULT_TEMPLATE}
        />
      )}

      {promptTemplate !== null && (
        <button
          onClick={() => setPromptTemplate(null)}
          className="text-xs text-archive-ink/50 hover:text-archive-ink underline"
        >
          Reset to default
        </button>
      )}
    </div>
  );
};
```

---

## State of the Art

| Old Approach | Current Approach | Status |
|--------------|-----------------|--------|
| Hardcoded German prompt in `legacy/config.py` | `_generate_prompt()` in `OcrEngine` (dynamic field enumeration) | Exists but not user-editable |
| N/A | User-configurable `prompt_template` per template/batch | This phase |

**What stays the same:**
- Field names continue to be the primary configuration surface.
- The VLM, API call structure, and JSON response parsing are unchanged.
- Templates are still stored in `data/templates.json` as a flat JSON array.

---

## Open Questions

1. **Should `prompt_template` be stored per-batch or only per-template?**
   - What we know: Templates persist long-term; batches are one-time runs with a snapshot of config.
   - What's unclear: Whether users want to batch-level override a template's prompt independently of the template itself.
   - Recommendation: Store on both `Template` and in `config.json` (per-batch snapshot). The batch value is set at creation time from whatever the UI had at that moment. This matches how `fields` already works.

2. **Should the default template be editable via env/settings, or only per-batch?**
   - What we know: `settings.EXTRACTION_PROMPT` in `config.py` is the current default (a multi-line string). It is not exposed via any API.
   - What's unclear: Whether the user wants a "global default" that all new batches inherit when no per-batch template is set.
   - Recommendation: Leave `settings.EXTRACTION_PROMPT` as the coded fallback. Do not expose it through the API. The per-batch/per-template `prompt_template` field covers the common case. Phase 5 can address global defaults if needed.

3. **What language should the default template use?**
   - What we know: Current hardcoded prompts are in German (matching the museum archive domain). The existing `EXTRACTION_PROMPT` in `config.py` is fully German.
   - What's unclear: Whether this phase should maintain German or introduce language-agnostic defaults.
   - Recommendation: Keep the default template in German to preserve continuity. Users who need English can override via the new editor.

4. **Should template rendering be validated server-side before persisting?**
   - Recommendation: No. This is an internal research tool, not a multi-tenant SaaS. Validation in the UI (hint + live preview) is sufficient. Server-side validation adds complexity with no security benefit.

---

## Sources

### Primary (HIGH confidence)
- Direct inspection of `apps/backend/app/services/ocr_engine.py` — `_generate_prompt()` implementation
- Direct inspection of `apps/backend/app/services/template_service.py` — Template CRUD persistence
- Direct inspection of `apps/backend/app/services/batch_manager.py` — `create_batch()` + `config.json` write
- Direct inspection of `apps/backend/app/api/api_v1/endpoints/batches.py` — `run_ocr_task()` config.json read
- Direct inspection of `apps/backend/app/models/schemas.py` — current Pydantic model definitions
- Direct inspection of `apps/backend/app/core/config.py` — `EXTRACTION_PROMPT` default + `FIELD_KEYS`
- Direct inspection of `packages/shared-types/schemas/*.schema.json` — JSON Schema source of truth
- Direct inspection of `packages/shared-types/scripts/generate.mjs` — codegen pipeline
- Direct inspection of `apps/frontend/src/store/wizardStore.ts` — current Zustand state shape
- Direct inspection of `apps/frontend/src/features/configure/FieldManager.tsx` — Configure step UI
- Direct inspection of `apps/frontend/src/features/configure/TemplateSelector.tsx` — template loading flow
- Direct inspection of `apps/frontend/src/api/templatesApi.ts` — frontend template API calls

### Secondary (MEDIUM confidence)
- `.planning/STATE.md` Key Decisions section — confirms "JSON Schema as source of truth" decision and codegen workflow
- `.planning/ROADMAP.md` — confirms phase dependencies and FR2/FR3 requirements

---

## Metadata

**Confidence breakdown:**
- Current system behaviour: HIGH — inspected all relevant files directly
- Change scope: HIGH — all layers identified with exact file paths and line-level context
- Prompt engineering impact: MEDIUM — whether the new template improves VLM extraction quality over the current hardcoded prompt depends on what the user writes; the infrastructure change is low-risk
- Backward compatibility: HIGH — `config.get("prompt_template")` with `None` fallback is the established pattern already used for `fields`

**Research date:** 2026-02-22
**Valid until:** 2026-03-22 (stable codebase; no external library tracking needed)
